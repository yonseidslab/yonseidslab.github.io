---
layout: post
title: "Titanic 생존 예측 문제"
author: "JeonghyunGan"
categories: [Projects, Kaggle]
---

같이 파이썬/머신러닝 스터디를 하는 친구들과 미니 프로젝트로 캐글 타이타닉 생존 문제를 풀어봤다. 로지스틱 회귀를 공부하고 진행한 프로젝트라 로지스틱 회귀로 문제에 접근했고, 정확도 점수는 약 0.76정도 나왔다. 등수로는 8천 등 정도인데 1점을 받은 사람들은 어떻게 한건지 궁금하다. 제한된 시간 안에 결과를 내려다보니 모델을 만드는데만 급급하고 EDA에는 정성스럽게 하지 못한 것 같다. 스터디에서 다른 모델들을 다룬 후에 EDA/다른 모델들과 비교해볼 예정이다.

### 0. 데이터/라이브러리 불러오기

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
```

### 1. 전처리 과정

- `train`과 `test`를 합치고 `PassengerId`를 인덱스로 돌림
- 캐비넷을 사용/사용하지 않음의 이진 변수로 재코딩
- 결측이 있는 `Age`, `Fare`에 값 채워넣기
- 사용하지 않을 컬럼 드롭
- 성별을 0,1로 재코딩
- 범주형 변수들 OneHot 인코딩 적용
- 인덱스를 통해 다시 train/test 분리
- `x_train`, `y_train` 분리하고 `sklearn`에서 사용 가능한 `np.array`로 변형

```python
data = pd.concat([train, test]).set_index('PassengerId')

data.Cabin = data.Cabin.notnull() * 1
data.Age = data.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.mean()))
data.Fare = data.groupby(['Pclass', 'Sex'])['Fare'].apply(lambda x: x.fillna(x.mean()))

dropcols = ['Name', 'Ticket']
data.drop(dropcols, axis = 1, inplace=True)

data = data.replace(['male', 'female'], [0,1])

data = pd.get_dummies(data)

train = data.loc[train.PassengerId]
test = data.loc[test.PassengerId]

x_train = train.drop("Survived", axis = 1).values
y_train = train.Survived.values
x_test = test.drop("Survived", axis = 1).values
```

### 2. 모델 적합, 예측, 결과 저장

```python
clf = LogisticRegression().fit(x_train, y_train)
y_pred = clf.predict(x_test).astype(int)
result = pd.DataFrame({"PassengerId":test.index, "Survived":y_pred})
result.to_csv("result.csv", index=False)
```
